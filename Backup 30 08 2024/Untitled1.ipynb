{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import skfuzzy as fuzz\n",
    "from skfuzzy import control as ctrl\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def setup_fuzzy_system():\n",
    "    cross_border = ctrl.Antecedent(np.arange(0, 1.1, 0.1), 'cross_border')\n",
    "    country_risk = ctrl.Antecedent(np.arange(0, 1.1, 0.1), 'country_risk')\n",
    "    pep_involvement = ctrl.Antecedent(np.arange(0, 1.1, 0.1), 'pep_involvement')\n",
    "    transaction_type = ctrl.Antecedent(np.arange(0, 3, 1), 'transaction_type')\n",
    "    \n",
    "    # Consequent\n",
    "    risk = ctrl.Consequent(np.arange(0, 101, 1), 'risk')\n",
    "\n",
    "    # Membership Functions\n",
    "    pep_involvement['no'] = fuzz.trapmf(pep_involvement.universe, [0, 0, 0.3, 0.5])\n",
    "    pep_involvement['yes'] = fuzz.trapmf(pep_involvement.universe, [0.5, 0.7, 1, 1])\n",
    "    \n",
    "    cross_border['low'] = fuzz.trapmf(cross_border.universe, [0, 0, 0.3, 0.5])\n",
    "    cross_border['high'] = fuzz.trapmf(cross_border.universe, [0.5, 0.7, 1, 1])\n",
    "    \n",
    "    country_risk['low'] = fuzz.trapmf(country_risk.universe, [0, 0, 0.3, 0.5])\n",
    "    country_risk['high'] = fuzz.trapmf(country_risk.universe, [0.5, 0.7, 1, 1])\n",
    "\n",
    "    transaction_type['crypto_transfer'] = fuzz.trimf(transaction_type.universe, [0, 0, 1])\n",
    "    transaction_type['payment'] = fuzz.trimf(transaction_type.universe, [1, 1, 2])\n",
    "    transaction_type['other'] = fuzz.trimf(transaction_type.universe, [2, 2, 2])\n",
    "\n",
    "    risk['low'] = fuzz.trimf(risk.universe, [0, 0, 50])\n",
    "    risk['medium'] = fuzz.trimf(risk.universe, [20, 50, 80])\n",
    "    risk['high'] = fuzz.trimf(risk.universe, [60, 100, 100])\n",
    "    \n",
    "    \n",
    "#     cross_border = ctrl.Antecedent(np.arange(0, 2, 1), 'cross_border')\n",
    "#     country_risk = ctrl.Antecedent(np.arange(0, 2, 1), 'country_risk')\n",
    "#     pep_involvement = ctrl.Antecedent(np.arange(0, 2, 1), 'pep_involvement')\n",
    "#     transaction_type = ctrl.Antecedent(np.arange(0, 3, 1), 'transaction_type')\n",
    "\n",
    "#     pep_involvement['no'] = fuzz.trimf(pep_involvement.universe, [0, 0, 0.5])\n",
    "#     pep_involvement['yes'] = fuzz.trimf(pep_involvement.universe, [0.5, 1, 1])\n",
    "#     cross_border['low'] = fuzz.trimf(cross_border.universe, [0, 0, 1])\n",
    "#     cross_border['high'] = fuzz.trimf(cross_border.universe, [0, 1, 1])\n",
    "#     country_risk['low'] = fuzz.trimf(country_risk.universe, [0, 0, 1])\n",
    "#     country_risk['high'] = fuzz.trimf(country_risk.universe, [0, 1, 1])\n",
    "#     transaction_type['crypto_transfer'] = fuzz.trimf(transaction_type.universe, [0, 0, 1])\n",
    "#     transaction_type['payment'] = fuzz.trimf(transaction_type.universe, [1, 1, 2])\n",
    "#     transaction_type['other'] = fuzz.trimf(transaction_type.universe, [2, 2, 2])\n",
    "\n",
    "    risk = ctrl.Consequent(np.arange(0, 101, 1), 'risk')\n",
    "    risk['low'] = fuzz.trimf(risk.universe, [0, 0, 40])\n",
    "    risk['medium'] = fuzz.trimf(risk.universe, [30, 50, 70])\n",
    "    risk['high'] = fuzz.trimf(risk.universe, [60, 100, 100])\n",
    "\n",
    "    rule1 = ctrl.Rule(transaction_type['crypto_transfer'] | transaction_type['payment'], risk['high'])\n",
    "    rule2 = ctrl.Rule(pep_involvement['yes'] | country_risk['high'], risk['high'])\n",
    "    rule3 = ctrl.Rule(cross_border['high'], risk['medium'])\n",
    "    rule4 = ctrl.Rule(cross_border['low'] & transaction_type['other'], risk['low'])\n",
    "\n",
    "    aml_control = ctrl.ControlSystem([rule1, rule2, rule3, rule4])\n",
    "    aml_sim = ctrl.ControlSystemSimulation(aml_control)\n",
    "    return aml_sim\n",
    "\n",
    "def evaluate_transaction(row, aml_sim):\n",
    "    transaction_type_map = {'CRYPTO-TRANSFER': 1, 'PAYMENT': 1, 'OTHER': 2}\n",
    "    transaction_type_value = transaction_type_map.get(row['Transaction_Type'], 2)\n",
    "    pep_involvement_value = 1 if row['Bene_Is_Pep'] or row['Sender_Is_Pep'] else 0\n",
    "    cross_border_value = 1 if row['Sender_Country'] != row['Bene_Country'] else 0\n",
    "    high_risk_countries = ['Iran', 'Syria', 'North-Korea']\n",
    "    country_risk_value = 1 if row['Bene_Country'] in high_risk_countries else 0\n",
    "\n",
    "    aml_sim.input['transaction_type'] = transaction_type_value\n",
    "    aml_sim.input['pep_involvement'] = pep_involvement_value\n",
    "    aml_sim.input['cross_border'] = cross_border_value\n",
    "    aml_sim.input['country_risk'] = country_risk_value\n",
    "\n",
    "    aml_sim.compute()\n",
    "    risk_score = aml_sim.output['risk']\n",
    "\n",
    "    reasons = []\n",
    "    if transaction_type_value == 1:\n",
    "        reasons.append('Transaction type: High-risk transaction (crypto transfer/payment)')\n",
    "    if pep_involvement_value == 1:\n",
    "        reasons.append('PEP involvement')\n",
    "    if cross_border_value == 1:\n",
    "        reasons.append('Cross-border transaction')\n",
    "    if country_risk_value == 1:\n",
    "        reasons.append('High-risk country involvement')\n",
    "\n",
    "    return risk_score, reasons\n",
    "\n",
    "class EdgeGCN_LSTM(nn.Module):\n",
    "    def __init__(self, hidden_channels, lstm_hidden_channels, out_channels, dropout_rate):\n",
    "        super(EdgeGCN_LSTM, self).__init__()\n",
    "        self.conv1 = GCNConv(1, hidden_channels)\n",
    "        self.lstm = nn.LSTM(input_size=hidden_channels * 2 + 3, hidden_size=lstm_hidden_channels, batch_first=True)\n",
    "        self.lin = nn.Linear(lstm_hidden_channels, out_channels)\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = F.dropout(F.relu(self.conv1(x, edge_index)), p=self.dropout_rate, training=self.training)\n",
    "        sender_features = x[edge_index[0]]\n",
    "        receiver_features = x[edge_index[1]]\n",
    "        edge_features = torch.cat([sender_features, receiver_features, edge_attr], dim=1)\n",
    "        edge_features = edge_features.unsqueeze(0)\n",
    "        lstm_out, _ = self.lstm(edge_features)\n",
    "        lstm_out = lstm_out.squeeze(0)\n",
    "        out = self.lin(lstm_out)\n",
    "        return out.view(-1)\n",
    "\n",
    "class GraphDataProcessor:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.aml_sim = setup_fuzzy_system()\n",
    "\n",
    "    def evaluate_risk_scores(self):\n",
    "        results = self.df.apply(lambda row: evaluate_transaction(row, self.aml_sim), axis=1)\n",
    "        self.df['Risk_Score'], self.df['Risk_Reasons'] = zip(*results)\n",
    "\n",
    "    def prepare_graph_data(self):\n",
    "        self.evaluate_risk_scores()\n",
    "        self.df['Time_step'] = pd.to_datetime(self.df['Time_step'])\n",
    "        self.df = self.df.sort_values(by=['Sender_Customer_Id', 'Time_step'])\n",
    "        self.df['Label'] = pd.to_numeric(self.df['Label'], errors='coerce').fillna(0).astype(int)\n",
    "        \n",
    "        all_ids = pd.concat([self.df['Sender_Customer_Id'], self.df['Bene_Customer_Id']]).unique()\n",
    "        id_map = {id: idx for idx, id in enumerate(all_ids)}\n",
    "\n",
    "        sender_customer_mapped = self.df['Sender_Customer_Id'].map(id_map).values\n",
    "        bene_customer_mapped = self.df['Bene_Customer_Id'].map(id_map).values\n",
    "\n",
    "        edge_index = torch.tensor(\n",
    "            np.array([sender_customer_mapped, bene_customer_mapped]), \n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        node_features = torch.zeros((len(all_ids), 1))\n",
    "\n",
    "        transaction_type_encoded = torch.tensor(\n",
    "            pd.to_numeric(LabelEncoder().fit_transform(self.df['Transaction_Type']), errors='coerce').astype(float),\n",
    "            dtype=torch.float\n",
    "        ).view(-1, 1)\n",
    "\n",
    "        self.df['USD_Amount'] = pd.to_numeric(self.df['USD_Amount'], errors='coerce')\n",
    "        usd_amount_np = StandardScaler().fit_transform(self.df[['USD_Amount']].astype(float))\n",
    "        usd_amount = torch.tensor(usd_amount_np, dtype=torch.float).view(-1, 1)\n",
    "        \n",
    "        risk_score = torch.tensor(\n",
    "            pd.to_numeric(self.df['Risk_Score'].apply(lambda x: x[0] if isinstance(x, (list, tuple)) else x),\n",
    "            errors='coerce').astype(float),\n",
    "            dtype=torch.float\n",
    "        ).view(-1, 1)\n",
    "\n",
    "        edge_attr = torch.cat([transaction_type_encoded, usd_amount, risk_score], dim=1)\n",
    "\n",
    "        edge_labels = torch.tensor(\n",
    "            pd.to_numeric(self.df['Label'], errors='coerce').astype(int).values,\n",
    "            dtype=torch.long\n",
    "        )\n",
    "\n",
    "        return Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr, y=edge_labels)\n",
    "\n",
    "def process_message(data, model, device, output_directory):\n",
    "    try:\n",
    "        logging.info(\"Preparing DataFrame from input data\")\n",
    "        df = pd.DataFrame(data)\n",
    "        logging.info(f\"DataFrame created with {len(df)} rows\")\n",
    "\n",
    "        logging.info(\"Preparing graph data\")\n",
    "        processor = GraphDataProcessor(df)\n",
    "        graph_data = processor.prepare_graph_data().to(device)\n",
    "        logging.info(f\"Graph data prepared with {graph_data.num_nodes} nodes and {graph_data.num_edges} edges\")\n",
    "\n",
    "        logging.info(\"Evaluating model\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(graph_data.x, graph_data.edge_index, graph_data.edge_attr)\n",
    "            predictions = torch.sigmoid(output).cpu().numpy()\n",
    "            predictions = predictions.flatten()\n",
    "            logging.info(f\"Predictions obtained with length {len(predictions)}\")\n",
    "\n",
    "        df['Predictions'] = predictions\n",
    "        df['Label_Prediction'] = (predictions >= 0.5).astype(int)\n",
    "\n",
    "        # Include reasons for risk scores\n",
    "        df['Risk_Reasons'] = df['Risk_Reasons'].apply(lambda reasons: ' | '.join(reasons))\n",
    "\n",
    "        output_file = os.path.join(output_directory, f'processed_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv')\n",
    "        df.to_csv(output_file, index=False)\n",
    "        logging.info(f\"Results written to {output_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing message: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
